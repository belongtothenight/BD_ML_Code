{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import math\n",
    "import json\n",
    "import inspect\n",
    "import concurrent.futures as cf  # doesn't work with sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as copy\n",
    "import statistics as stt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from os import system, getcwd, startfile\n",
    "from os.path import join\n",
    "from time import time\n",
    "from scipy.io import arff\n",
    "from sklearn import tree, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "\n",
    "class main():\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        print('class initialized')\n",
    "\n",
    "    def get_data(self, dataset='random', show_fig=False, test_size=0.5, random_state=2018):\n",
    "        def generate_random_data(n, m):\n",
    "            X = np.random.rand(n, m)\n",
    "            y = np.random.randint(2, size=n)\n",
    "            return X, y\n",
    "\n",
    "        def two_blob_data(size=100):\n",
    "            # X\n",
    "            np.random.seed(2000)\n",
    "            X1 = np.random.normal(4.5, 1.3, size)\n",
    "            Y1 = np.random.normal(2.0, 0.8, size) + X1\n",
    "            X2 = X1 + np.random.normal(0.01, 0.3, size)\n",
    "            Y2 = Y1 + 8.0\n",
    "            X = np.append(X1, X2)\n",
    "            Y = np.append(Y1, Y2)\n",
    "            X = np.append(X, Y)\n",
    "            X = X.reshape(2, size*2).T\n",
    "            # y\n",
    "            y1 = [1 for i in range(size)]\n",
    "            y2 = [0 for i in range(size)]\n",
    "            y = np.append(y1, y2)\n",
    "            return X, y\n",
    "\n",
    "        def import_wdbc():\n",
    "            path = join(getcwd().rstrip(\n",
    "                'src'), 'data/wdbc.data').replace('\\\\', '/')\n",
    "            data = pd.read_csv(path, header=None)\n",
    "            wdbc_columns = ['id', 'malignant',\n",
    "                            'nucleus_mean', 'nucleus_se', 'nucleus_worst',\n",
    "                            'texture_mean', 'texture_se', 'texture_worst',\n",
    "                            'perimeter_mean', 'perimeter_se', 'perimeter_worst',\n",
    "                            'area_mean', 'area_se', 'area_worst',\n",
    "                            'smoothness_mean', 'smoothness_se', 'smoothness_worst',\n",
    "                            'compactness_mean', 'compactness_se', 'compactness_worst',\n",
    "                            'concavity_mean', 'concavity_se', 'concavity_worst',\n",
    "                            'concave_pts_mean', 'concave_pts_se', 'concave_pts_worst',\n",
    "                            'symmetry_mean', 'symmetry_se', 'symmetry_worst',\n",
    "                            'fractal_dim_mean', 'fractal_dim_se', 'fractal_dim_worst']\n",
    "            data.columns = wdbc_columns\n",
    "            data['malignant'] = data['malignant'].map(\n",
    "                lambda x: 0 if x == 'B' else 1)\n",
    "            X = data.drop(['id', 'malignant'], axis=1).values\n",
    "            s = StandardScaler()\n",
    "            X = s.fit_transform(X)\n",
    "            y = data['malignant'].values\n",
    "            return X, y\n",
    "\n",
    "        def import_MNIST():\n",
    "            # not working\n",
    "            digits = datasets.load_digits()\n",
    "            X = digits.data\n",
    "            y = digits.target\n",
    "            return X, y\n",
    "        \n",
    "        if dataset == 'random':\n",
    "            self.X, self.y = generate_random_data(1000, 100)\n",
    "        elif dataset == 'blob':\n",
    "            self.X, self.y = two_blob_data(1000)\n",
    "        elif dataset == 'wbcd':\n",
    "            self.X, self.y = import_wdbc()\n",
    "        elif dataset == 'MNIST':\n",
    "            self.X, self.y = import_MNIST()\n",
    "        else:\n",
    "            print('dataset not found')\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        if show_fig:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.scatter(self.X[:, 0], self.X[:, 1], c=self.y)\n",
    "            plt.show()\n",
    "\n",
    "    def NN(self, model=1, epochs=10, batch_size=32):\n",
    "        def data_preprocessing():\n",
    "            # one hot encoding\n",
    "            y_train = np_utils.to_categorical(self.y_train)\n",
    "            y_test = np_utils.to_categorical(self.y_test)\n",
    "            # # normalization\n",
    "            # self.X_train = self.X_train.astype('float32')\n",
    "            # self.X_test = self.X_test.astype('float32')\n",
    "            # self.X_train /= 255\n",
    "            # self.X_test /= 255\n",
    "            return y_train, y_test\n",
    "\n",
    "        def build_model1():\n",
    "            model = Sequential()\n",
    "            N_Features = self.X_train.shape[1]\n",
    "            model.add(Dense(N_Features, activation='relu'))\n",
    "            model.add(Dense(2, activation='softmax'))\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer='adam', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        def build_model2():\n",
    "            # https://stackoverflow.com/questions/61742556/valueerror-shapes-none-1-and-none-2-are-incompatible\n",
    "            # https: // github.com/fchollet/deep-learning-with -python-notebooks/issues/157\n",
    "            model = Sequential()\n",
    "            N_Features = self.X_train.shape[1]\n",
    "            model.add(Dense(N_Features, activation='relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.add(Flatten())\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        def build_model3():\n",
    "            # https: // stackoverflow.com/questions/37213388/keras-accuracy-does-not -change\n",
    "            # https://keras.io/api/optimizers/\n",
    "            model = Sequential()\n",
    "            N_Features = self.X_train.shape[1]\n",
    "            model.add(Dense(N_Features, activation='relu'))\n",
    "            model.add(Dense(N_Features*2, activation='relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.add(Flatten())\n",
    "            opt = SGD(lr=0.00001)\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='Ftrl', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        def evaluate_result(y_pred):\n",
    "            y_pred = np.array([int(x < y) for [x, y] in y_pred])\n",
    "            acc = accuracy_score(self.y_test, y_pred)\n",
    "            prc = precision_score(self.y_test, y_pred)\n",
    "            rec = recall_score(self.y_test, y_pred)\n",
    "            f1 = f1_score(self.y_test, y_pred)\n",
    "            print('accuracy: ', acc)\n",
    "            print('precision: ', prc)\n",
    "            print('recall: ', rec)\n",
    "            print('f1: ', f1)\n",
    "            return [acc, prc, rec, f1]\n",
    "\n",
    "        y_train, y_test = data_preprocessing()\n",
    "\n",
    "        if model == 1:\n",
    "            model = build_model1()\n",
    "        elif model == 2:\n",
    "            model = build_model2()\n",
    "        elif model == 3:\n",
    "            model = build_model3()\n",
    "        \n",
    "        model.fit(self.X_train, y_train, validation_data=(\n",
    "            self.X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    "        print(model.summary())\n",
    "        # https://stackoverflow.com/questions/49527159/how-to-get-the-output-shape-of-a-layer-in-keras\n",
    "        # https://www.activestate.com/resources/quick-reads/what-is-a-keras-model/\n",
    "        # https://stackoverflow.com/questions/45799474/keras-model-evaluate-vs-model-predict-accuracy-difference-in-multi-class-nlp-ta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the following homework\n",
    "----------------\n",
    "\n",
    "1. Modify your first_ANN to have only one output neuron and make the necessary changes on your first_ANN.\n",
    "    - make sure your program is running properly.\n",
    "- Use Wisconsin breast cancer data for your first_ANN\n",
    "- Try MNIST digit data with your first_ANN.   MNIST digit data set is available in:\n",
    "    - //www.kaggle.com/c/digit-recognizer/data   or\n",
    "    - datasets.load_digits() can read dataset comes with sklearn\n",
    "        - you need to import datasets package to be capable ot load_digites:\n",
    "            - from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Modify ANN to have only one output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class initialized\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 6ms/step - loss: 1.0046 - accuracy: 0.5000 - val_loss: 0.9147 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8516 - accuracy: 0.5000 - val_loss: 0.7979 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.5000 - val_loss: 0.7374 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.5000 - val_loss: 0.7108 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.5000 - val_loss: 0.7019 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.5000 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5000 - val_loss: 0.6970 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.5000 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.5000 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5000 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = main()\n",
    "m.get_data(dataset='blob', show_fig=False)\n",
    "m.NN(model=2, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Use Wisconsin breast cancer data for your ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class initialized\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dachu\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (1, 30)                   930       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (1, 60)                   1860      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (1, 1)                    61        \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (1, 1)                    0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,851\n",
      "Trainable params: 2,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = main()\n",
    "m.get_data(dataset='wbcd', show_fig=False)\n",
    "m.NN(model=3, epochs=10, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Use MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class initialized\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 2s 1ms/step - loss: 0.4703 - accuracy: 0.8688 - val_loss: 0.3725 - val_accuracy: 0.8991\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3560 - accuracy: 0.8956 - val_loss: 0.3478 - val_accuracy: 0.8982\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3410 - accuracy: 0.9000 - val_loss: 0.3359 - val_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3345 - accuracy: 0.9000 - val_loss: 0.3325 - val_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3321 - accuracy: 0.9000 - val_loss: 0.3321 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3324 - accuracy: 0.9000 - val_loss: 0.3320 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3303 - accuracy: 0.9000 - val_loss: 0.3297 - val_accuracy: 0.8991\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.9000 - val_loss: 0.3284 - val_accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3295 - accuracy: 0.9000 - val_loss: 0.3281 - val_accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 1s 1ms/step - loss: 0.3282 - accuracy: 0.9000 - val_loss: 0.3278 - val_accuracy: 0.9000\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (1, 64)                   4160      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (1, 1)                    65        \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (1, 1)                    0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,225\n",
      "Trainable params: 4,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = main()\n",
    "m.get_data(dataset='MNIST', show_fig=False)\n",
    "m.NN(model=2, epochs=10, batch_size=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
