{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e9cb12",
   "metadata": {},
   "source": [
    "# 1. Download new_train.csv (don't worry about new_test.csv) from the following website.\n",
    "--------\n",
    "https://www.kaggle.com/code/rashmiranu/banking-dataset-eda-and-binary-classification/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319f8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import concurrent.futures as cf # doesn't work with sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as copy\n",
    "import statistics as stt\n",
    "import seaborn as sns\n",
    "from os import system, getcwd, startfile\n",
    "from os.path import join\n",
    "from time import time\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd417e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = join(getcwd().rstrip('src'), 'data/banking_dataset_classification_train.csv').replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016bb5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# src: https://stackoverflow.com/questions/31328861/python-pandas-replacing-header-with-top-row\n",
    "data = pd.read_csv(src_path, header=None, low_memory=False)\n",
    "header = data.iloc[0]\n",
    "data = data[1:]\n",
    "data.columns = header\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d497f",
   "metadata": {},
   "source": [
    "# 2. There are some numerical and object columns.  Find out the columns which are highest correlated to 'y' columns for both numerical and object columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3390cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numerical object to int64\n",
    "data['age'] = data['age'].astype('int64')\n",
    "data['duration'] = data['duration'].astype('int64')\n",
    "data['campaign'] = data['campaign'].astype('int64')\n",
    "data['pdays'] = data['pdays'].astype('int64')\n",
    "data['previous'] = data['previous'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f87463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datatype\n",
    "result = data.dtypes\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20055f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change datatype\n",
    "# src: https://stackoverflow.com/questions/51241575/calculate-correlation-between-columns-of-strings\n",
    "# src: https://stackoverflow.com/questions/51102205/how-to-know-the-labels-assigned-by-astypecategory-cat-codes\n",
    "columns = data.columns\n",
    "column_dict = []\n",
    "for x in columns:\n",
    "    c = data[x].astype('category')\n",
    "    d = dict(enumerate(c.cat.categories))\n",
    "    column_dict.append(d)\n",
    "    data[x] = data[x].astype('category').cat.codes\n",
    "data_corr = data.corr()\n",
    "data_corr.sort_values('y', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726513c0",
   "metadata": {},
   "source": [
    "### Numerical Columns\n",
    "| column | y corr value | highest |\n",
    "| :-: | - ||\n",
    "| age | 0.028620 ||\n",
    "| duration | 0.079003 ||\n",
    "| campaign | -0.051431 ||\n",
    "| pdays | -0.238267 ||\n",
    "| previous | 0.229759 | $\\star$ |\n",
    "\n",
    "### Object Columns\n",
    "| column | y corr value | highest |\n",
    "| :-: | - ||\n",
    "| job | 0.026276 ||\n",
    "| marital | 0.050084 ||\n",
    "| education |0.059263||\n",
    "| default |-0.099142||\n",
    "| housing |0.009821||\n",
    "| loan |-0.000452||\n",
    "| contact |-0.143238||\n",
    "| month |-0.007508||\n",
    "| day_of_week |0.011926||\n",
    "| poutcome |0.127784|$\\star$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cf7ae",
   "metadata": {},
   "source": [
    "# 3. Convert object columns, esp. the one that is highly correlated to 'y' column, to numerical so that it can be included in ML.\n",
    "<!-- All columns will be converted. I'll use the correlation numbers in q4 to improve recall rate. -->\n",
    "All data had been converted to numbers back in step 2.\n",
    "The followings are the convertion labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('job:\\t' + str(json.dumps(column_dict[1], indent=4)))\n",
    "print('marital:\\t' + str(json.dumps(column_dict[2], indent=4)))\n",
    "print('education:\\t' + str(json.dumps(column_dict[3], indent=4)))\n",
    "print('default:\\t' + str(json.dumps(column_dict[4], indent=4)))\n",
    "print('housing:\\t' + str(json.dumps(column_dict[5], indent=4)))\n",
    "print('loan:\\t' + str(json.dumps(column_dict[6], indent=4)))\n",
    "print('contact:\\t' + str(json.dumps(column_dict[7], indent=4)))\n",
    "print('month:\\t' + str(json.dumps(column_dict[8], indent=4)))\n",
    "print('day_of_week:\\t' + str(json.dumps(column_dict[9], indent=4)))\n",
    "print('poutcome:\\t' + str(json.dumps(column_dict[14], indent=4)))\n",
    "print('y:\\t' + str(json.dumps(column_dict[15], indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73599a9",
   "metadata": {},
   "source": [
    "# 4. Explore the option of class_weight and anything you can do to improve recall rate for SVM and logistic regression to some reasonable value (try to keep precision to be better than 30%).\n",
    "Approach: [include cross validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e515bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X, y\n",
    "y = data.y\n",
    "X = data.drop(columns='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X\n",
    "s = StandardScaler()\n",
    "X = s.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set\n",
    "# train : cross_validation : test = 6 : 2 : 2\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=2018)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=2018)\n",
    "train_len = len(X_train)\n",
    "cv_len = len(X_cv)\n",
    "test_len = len(X_test)\n",
    "total_len = len(data)\n",
    "print('Percentage of Train set : CV set : Test set = {0} : {1} : {2}'.format(train_len/total_len*100, cv_len/total_len*100, test_len/total_len*100))\n",
    "splitted_data = [X_train, y_train, X_cv, y_cv, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_data, y_pred):\n",
    "    accuracy = accuracy_score(y_data, y_pred)\n",
    "    precision = precision_score(y_data, y_pred)\n",
    "    recall = recall_score(y_data, y_pred)\n",
    "    f1 = f1_score(y_data, y_pred)\n",
    "    return [accuracy, precision, recall, f1]\n",
    "\n",
    "def deploy_model(data, result=[], cv=True, default=False):\n",
    "    data[0] = X_train\n",
    "    data[1] = y_train\n",
    "    data[2] = X_cv\n",
    "    data[3] = y_cv\n",
    "    data[4] = X_test\n",
    "    data[5] = y_test\n",
    "\n",
    "    # Logistic Regression\n",
    "    if default:\n",
    "        model = LogisticRegression()\n",
    "    else:\n",
    "        model = LogisticRegression(class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    if cv:\n",
    "        y_pred = model.predict(X_cv)\n",
    "        eva_result = evaluation(y_cv, y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        eva_result = evaluation(y_test, y_pred)\n",
    "    result.append(['LR'] + eva_result)\n",
    "\n",
    "    # Decision Tree\n",
    "    if default:\n",
    "        model = DecisionTreeClassifier()\n",
    "    else:\n",
    "        model = DecisionTreeClassifier(class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    if cv:\n",
    "        y_pred = model.predict(X_cv)\n",
    "        eva_result = evaluation(y_cv, y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        eva_result = evaluation(y_test, y_pred)\n",
    "    result.append(['DT'] + eva_result)\n",
    "\n",
    "    # Random Forest\n",
    "    if default:\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        model = RandomForestClassifier(class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    if cv:\n",
    "        y_pred = model.predict(X_cv)\n",
    "        eva_result = evaluation(y_cv, y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        eva_result = evaluation(y_test, y_pred)\n",
    "    result.append(['RF'] + eva_result)\n",
    "\n",
    "    # SVM\n",
    "    if default:\n",
    "        model = SVC()\n",
    "    else:\n",
    "        model = SVC(class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    if cv:\n",
    "        y_pred = model.predict(X_cv)\n",
    "        eva_result = evaluation(y_cv, y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        eva_result = evaluation(y_test, y_pred)\n",
    "    result.append(['SVM'] + eva_result)\n",
    "\n",
    "    # KNN\n",
    "    if default:\n",
    "        model = KNeighborsClassifier()\n",
    "    else:\n",
    "        model = KNeighborsClassifier(weights='distance')\n",
    "    model.fit(X_train, y_train)\n",
    "    if cv:\n",
    "        y_pred = model.predict(X_cv)\n",
    "        eva_result = evaluation(y_cv, y_pred)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        eva_result = evaluation(y_test, y_pred)\n",
    "    result.append(['KNN'] + eva_result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def result_evaluation(result):\n",
    "    result = pd.DataFrame(result, columns=['model', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "    df_LR = result[result['model'] == 'LR']\n",
    "    df_DT = result[result['model'] == 'DT']\n",
    "    df_RF = result[result['model'] == 'RF']\n",
    "    df_SVM = result[result['model'] == 'SVM']\n",
    "    df_KNN = result[result['model'] == 'KNN']\n",
    "    df_LR_dc = df_LR.describe()\n",
    "    df_DT_dc = df_DT.describe()\n",
    "    df_RF_dc = df_RF.describe()\n",
    "    df_SVM_dc = df_SVM.describe()\n",
    "    df_KNN_dc = df_KNN.describe()\n",
    "    print('LR------------------------------------------------')\n",
    "    print(df_LR_dc)\n",
    "    print('DT------------------------------------------------')\n",
    "    print(df_DT_dc)\n",
    "    print('RF------------------------------------------------')\n",
    "    print(df_RF_dc)\n",
    "    print('SVM-----------------------------------------------')\n",
    "    print(df_SVM_dc)\n",
    "    print('KNN-----------------------------------------------')\n",
    "    print(df_KNN_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation 1\n",
    "result = []\n",
    "for i in range(100):\n",
    "    result = deploy_model(splitted_data, result, True, False)\n",
    "result_evaluation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d105d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation 2\n",
    "result = []\n",
    "for i in range(100):\n",
    "    result = deploy_model(splitted_data, result, True, True)\n",
    "result_evaluation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test (settings from cross validation 1)\n",
    "final_result = []\n",
    "for i in range(100):\n",
    "    final_result = deploy_model(splitted_data, final_result, False)\n",
    "result_evaluation(final_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
