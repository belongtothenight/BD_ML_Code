{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import math\n",
    "import json\n",
    "import inspect\n",
    "import concurrent.futures as cf  # doesn't work with sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as copy\n",
    "import statistics as stt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from os import system, getcwd, startfile\n",
    "from os.path import join\n",
    "from time import time\n",
    "from scipy.io import arff\n",
    "from sklearn import tree, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "\n",
    "class main():\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        print('class initialized')\n",
    "\n",
    "    def get_data(self, dataset='random', show_fig=False, test_size=0.5, random_state=2018):\n",
    "        def generate_random_data(n, m):\n",
    "            X = np.random.rand(n, m)\n",
    "            y = np.random.randint(2, size=n)\n",
    "            return X, y\n",
    "\n",
    "        def two_blob_data(size=100):\n",
    "            # X\n",
    "            np.random.seed(2000)\n",
    "            X1 = np.random.normal(4.5, 1.3, size)\n",
    "            Y1 = np.random.normal(2.0, 0.8, size) + X1\n",
    "            X2 = X1 + np.random.normal(0.01, 0.3, size)\n",
    "            Y2 = Y1 + 8.0\n",
    "            X = np.append(X1, X2)\n",
    "            Y = np.append(Y1, Y2)\n",
    "            X = np.append(X, Y)\n",
    "            X = X.reshape(2, size*2).T\n",
    "            # y\n",
    "            y1 = [1 for i in range(size)]\n",
    "            y2 = [0 for i in range(size)]\n",
    "            y = np.append(y1, y2)\n",
    "            return X, y\n",
    "\n",
    "        def import_wdbc():\n",
    "            path = join(getcwd().rstrip(\n",
    "                'src'), 'data/wdbc.data').replace('\\\\', '/')\n",
    "            data = pd.read_csv(path, header=None)\n",
    "            wdbc_columns = ['id', 'malignant',\n",
    "                            'nucleus_mean', 'nucleus_se', 'nucleus_worst',\n",
    "                            'texture_mean', 'texture_se', 'texture_worst',\n",
    "                            'perimeter_mean', 'perimeter_se', 'perimeter_worst',\n",
    "                            'area_mean', 'area_se', 'area_worst',\n",
    "                            'smoothness_mean', 'smoothness_se', 'smoothness_worst',\n",
    "                            'compactness_mean', 'compactness_se', 'compactness_worst',\n",
    "                            'concavity_mean', 'concavity_se', 'concavity_worst',\n",
    "                            'concave_pts_mean', 'concave_pts_se', 'concave_pts_worst',\n",
    "                            'symmetry_mean', 'symmetry_se', 'symmetry_worst',\n",
    "                            'fractal_dim_mean', 'fractal_dim_se', 'fractal_dim_worst']\n",
    "            data.columns = wdbc_columns\n",
    "            data['malignant'] = data['malignant'].map(\n",
    "                lambda x: 0 if x == 'B' else 1)\n",
    "            X = data.drop(['id', 'malignant'], axis=1).values\n",
    "            s = StandardScaler()\n",
    "            X = s.fit_transform(X)\n",
    "            y = data['malignant'].values\n",
    "            return X, y\n",
    "\n",
    "        def import_MNIST():\n",
    "            # not working\n",
    "            digits = datasets.load_digits()\n",
    "            X = digits.data\n",
    "            y = digits.target\n",
    "            return X, y\n",
    "        \n",
    "        if dataset == 'random':\n",
    "            self.X, self.y = generate_random_data(1000, 100)\n",
    "        elif dataset == 'blob':\n",
    "            self.X, self.y = two_blob_data(1000)\n",
    "        elif dataset == 'wbcd':\n",
    "            self.X, self.y = import_wdbc()\n",
    "        elif dataset == 'MNIST':\n",
    "            self.X, self.y = import_MNIST()\n",
    "        else:\n",
    "            print('dataset not found')\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        if show_fig:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.scatter(self.X[:, 0], self.X[:, 1], c=self.y)\n",
    "            plt.show()\n",
    "\n",
    "    def NN(self, model=1, epochs=10, batch_size=32):\n",
    "        def data_preprocessing():\n",
    "            # one hot encoding\n",
    "            y_train = np_utils.to_categorical(self.y_train)\n",
    "            y_test = np_utils.to_categorical(self.y_test)\n",
    "            # # normalization\n",
    "            # self.X_train = self.X_train.astype('float32')\n",
    "            # self.X_test = self.X_test.astype('float32')\n",
    "            # self.X_train /= 255\n",
    "            # self.X_test /= 255\n",
    "            return y_train, y_test\n",
    "\n",
    "        def build_model1():\n",
    "            model = Sequential()\n",
    "            N_Features = self.X_train.shape[1]\n",
    "            model.add(Dense(N_Features, activation='relu'))\n",
    "            model.add(Dense(2, activation='softmax'))\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer='adam', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        def build_model2():\n",
    "            # https://stackoverflow.com/questions/61742556/valueerror-shapes-none-1-and-none-2-are-incompatible\n",
    "            # https: // github.com/fchollet/deep-learning-with -python-notebooks/issues/157\n",
    "            model = Sequential()\n",
    "            N_Features = self.X_train.shape[1]\n",
    "            model.add(Dense(N_Features, activation='relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.add(Flatten())\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        def build_model3():\n",
    "            # https: // stackoverflow.com/questions/37213388/keras-accuracy-does-not -change\n",
    "            # https://keras.io/api/optimizers/\n",
    "            model = Sequential()\n",
    "            N_Features = self.X_train.shape[1]\n",
    "            model.add(Dense(N_Features, activation='relu'))\n",
    "            model.add(Dense(N_Features*2, activation='relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.add(Flatten())\n",
    "            opt = SGD(lr=0.00001)\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='Ftrl', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        def build_model4():\n",
    "            # https://stackoverflow.com/questions/61742556/valueerror-shapes-none-1-and-none-2-are-incompatible\n",
    "            # https: // github.com/fchollet/deep-learning-with -python-notebooks/issues/157\n",
    "            model = Sequential()\n",
    "            N_Features = self.X_train.shape[1]\n",
    "            model.add(Dense(N_Features, activation='relu'))\n",
    "            model.add(Dense(10, activation='sigmoid'))\n",
    "            model.add(Flatten())\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        def evaluate_result(y_pred):\n",
    "            y_pred = np.array([int(x < y) for [x, y] in y_pred])\n",
    "            acc = accuracy_score(self.y_test, y_pred)\n",
    "            prc = precision_score(self.y_test, y_pred)\n",
    "            rec = recall_score(self.y_test, y_pred)\n",
    "            f1 = f1_score(self.y_test, y_pred)\n",
    "            print('accuracy: ', acc)\n",
    "            print('precision: ', prc)\n",
    "            print('recall: ', rec)\n",
    "            print('f1: ', f1)\n",
    "            return [acc, prc, rec, f1]\n",
    "\n",
    "        y_train, y_test = data_preprocessing()\n",
    "\n",
    "        if model == 1:\n",
    "            model = build_model1()\n",
    "        elif model == 2:\n",
    "            model = build_model2()\n",
    "        elif model == 3:\n",
    "            model = build_model3()\n",
    "        elif model == 4:\n",
    "            model = build_model4()\n",
    "        \n",
    "        model.fit(self.X_train, y_train, validation_data=(\n",
    "            self.X_test, y_test), epochs=epochs)\n",
    "        print(model.summary())\n",
    "        # https://stackoverflow.com/questions/49527159/how-to-get-the-output-shape-of-a-layer-in-keras\n",
    "        # https://www.activestate.com/resources/quick-reads/what-is-a-keras-model/\n",
    "        # https://stackoverflow.com/questions/45799474/keras-model-evaluate-vs-model-predict-accuracy-difference-in-multi-class-nlp-ta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the following homework\n",
    "----------------\n",
    "\n",
    "1. Modify your first_ANN to have only one output neuron and make the necessary changes on your first_ANN.\n",
    "    - make sure your program is running properly.\n",
    "- Use Wisconsin breast cancer data for your first_ANN\n",
    "- Try MNIST digit data with your first_ANN.   MNIST digit data set is available in:\n",
    "    - //www.kaggle.com/c/digit-recognizer/data   or\n",
    "    - datasets.load_digits() can read dataset comes with sklearn\n",
    "        - you need to import datasets package to be capable ot load_digites:\n",
    "            - from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Modify ANN to have only one output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class initialized\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = main()\n",
    "m.get_data(dataset='blob', show_fig=False)\n",
    "m.NN(model=2, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Use Wisconsin breast cancer data for your ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class initialized\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dachu\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 18ms/step - loss: 0.6963 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 60)                1860      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 61        \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,851\n",
      "Trainable params: 2,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = main()\n",
    "m.get_data(dataset='wbcd', show_fig=False)\n",
    "m.NN(model=3, epochs=10, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Use MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class initialized\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 6ms/step - loss: 1.6482 - accuracy: 0.0869 - val_loss: 0.5723 - val_accuracy: 0.1869\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.3096 - val_loss: 0.2714 - val_accuracy: 0.5161\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.6492 - val_loss: 0.1655 - val_accuracy: 0.7531\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.7851 - val_loss: 0.1239 - val_accuracy: 0.8443\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.8597 - val_loss: 0.1026 - val_accuracy: 0.8610\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.8820 - val_loss: 0.0888 - val_accuracy: 0.8832\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9098 - val_loss: 0.0784 - val_accuracy: 0.8943\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9220 - val_loss: 0.0723 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9298 - val_loss: 0.0671 - val_accuracy: 0.9055\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9443 - val_loss: 0.0631 - val_accuracy: 0.9132\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9510 - val_loss: 0.0597 - val_accuracy: 0.9188\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9510 - val_loss: 0.0568 - val_accuracy: 0.9188\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9577 - val_loss: 0.0539 - val_accuracy: 0.9266\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9655 - val_loss: 0.0520 - val_accuracy: 0.9321\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9666 - val_loss: 0.0503 - val_accuracy: 0.9388\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9699 - val_loss: 0.0478 - val_accuracy: 0.9410\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9722 - val_loss: 0.0459 - val_accuracy: 0.9444\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9744 - val_loss: 0.0446 - val_accuracy: 0.9455\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9733 - val_loss: 0.0435 - val_accuracy: 0.9466\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9710 - val_loss: 0.0436 - val_accuracy: 0.9477\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9777 - val_loss: 0.0412 - val_accuracy: 0.9544\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9766 - val_loss: 0.0407 - val_accuracy: 0.9555\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9811 - val_loss: 0.0395 - val_accuracy: 0.9544\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9811 - val_loss: 0.0401 - val_accuracy: 0.9544\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9722 - val_loss: 0.0394 - val_accuracy: 0.9522\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9822 - val_loss: 0.0385 - val_accuracy: 0.9544\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9822 - val_loss: 0.0370 - val_accuracy: 0.9644\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 0.9844 - val_loss: 0.0358 - val_accuracy: 0.9622\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9844 - val_loss: 0.0357 - val_accuracy: 0.9611\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9866 - val_loss: 0.0350 - val_accuracy: 0.9655\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9855 - val_loss: 0.0356 - val_accuracy: 0.9633\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9878 - val_loss: 0.0342 - val_accuracy: 0.9666\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9866 - val_loss: 0.0339 - val_accuracy: 0.9655\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9878 - val_loss: 0.0337 - val_accuracy: 0.9666\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9900 - val_loss: 0.0332 - val_accuracy: 0.9655\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9922 - val_loss: 0.0331 - val_accuracy: 0.9689\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9900 - val_loss: 0.0326 - val_accuracy: 0.9655\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9889 - val_loss: 0.0321 - val_accuracy: 0.9666\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9944 - val_loss: 0.0324 - val_accuracy: 0.9655\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9933 - val_loss: 0.0314 - val_accuracy: 0.9666\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9933 - val_loss: 0.0316 - val_accuracy: 0.9689\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9922 - val_loss: 0.0329 - val_accuracy: 0.9633\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9933 - val_loss: 0.0307 - val_accuracy: 0.9700\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0305 - val_accuracy: 0.9677\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9955 - val_loss: 0.0305 - val_accuracy: 0.9689\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9955 - val_loss: 0.0309 - val_accuracy: 0.9666\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0299 - val_accuracy: 0.9689\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0299 - val_accuracy: 0.9677\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9967 - val_loss: 0.0301 - val_accuracy: 0.9666\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0313 - val_accuracy: 0.9644\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0293 - val_accuracy: 0.9677\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.0292 - val_accuracy: 0.9677\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9689\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0288 - val_accuracy: 0.9689\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0286 - val_accuracy: 0.9711\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9711\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0289 - val_accuracy: 0.9722\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9677\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0284 - val_accuracy: 0.9700\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9677\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9711\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9700\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9666\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9733\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9711\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9955 - val_loss: 0.0277 - val_accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9744\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9711\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9744\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9755\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9755\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9722\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9744\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9733\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9744\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9733\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9755\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9744\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9744\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9744\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9733\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9755\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9744\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9744\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9744\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9744\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9733\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9755\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9744\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9755\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9755\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9755\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9755\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9744\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9744\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9744\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9755\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9744\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,810\n",
      "Trainable params: 4,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = main()\n",
    "m.get_data(dataset='MNIST', show_fig=False)\n",
    "m.NN(model=4, epochs=100, batch_size=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
