{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d5c831",
   "metadata": {},
   "source": [
    "# Explore the parameters of DT, RF, KNN, and SVM.  Find out the parameters that have significant effect on the accuracy.   This is an open question.  There is no standard answer.\n",
    "DT as [DecisionTree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)<br>\n",
    "RF as [RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)<br>\n",
    "KNN as [Kneighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)<br>\n",
    "SVC as [C-Support Vector Classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8dd1d",
   "metadata": {},
   "source": [
    "## Python Class for Function Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b0a1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system, getcwd\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print_flag = False\n",
    "print_result_flag = False\n",
    "plot_flag = False\n",
    "\n",
    "\n",
    "class algorithmOperation():\n",
    "    def get_data(self):\n",
    "        path = join(getcwd(), 'wdbc.data').replace('\\\\', '/')\n",
    "        self.data = pd.read_csv(path, header=None)\n",
    "        if print_flag:\n",
    "            print(self.data)\n",
    "            print(self.data.shape)\n",
    "            print(self.data.columns)\n",
    "            print(self.data.head())\n",
    "\n",
    "    def set_column_names(self):\n",
    "        column_names = ['id', 'malignant',\n",
    "                        'nucleus_mean', 'nucleus_se', 'nucleus_worst',\n",
    "                        'texture_mean', 'texture_se', 'texture_worst',\n",
    "                        'perimeter_mean', 'perimeter_se', 'perimeter_worst',\n",
    "                        'area_mean', 'area_se', 'area_worst',\n",
    "                        'smoothness_mean', 'smoothness_se', 'smoothness_worst',\n",
    "                        'compactness_mean', 'compactness_se', 'compactness_worst',\n",
    "                        'concavity_mean', 'concavity_se', 'concavity_worst',\n",
    "                        'concave_pts_mean', 'concave_pts_se', 'concave_pts_worst',\n",
    "                        'symmetry_mean', 'symmetry_se', 'symmetry_worst',\n",
    "                        'fractal_dim_mean', 'fractal_dim_se', 'fractal_dim_worst'\n",
    "                        ]\n",
    "\n",
    "        self.data.columns = column_names\n",
    "        if print_flag:\n",
    "            print(self.data.shape)\n",
    "            print(self.data.columns)\n",
    "            print(self.data.head())\n",
    "            self.data.tail(10)\n",
    "\n",
    "    def make_data_all_numerical(self):\n",
    "        self.data['malignant'] = self.data['malignant'].map(\n",
    "            lambda x: 0 if x == 'B' else 1)\n",
    "        if print_flag:\n",
    "            self.data.tail(10)\n",
    "\n",
    "    def split_data_into_train_test(self):\n",
    "        self.X = self.data.drop(columns=['malignant']).values\n",
    "        \n",
    "#         # for scaled data\n",
    "#         ss = StandardScaler()\n",
    "#         self.X = ss.fit_transform(self.X)\n",
    "        \n",
    "        self.y = self.data['malignant'].values\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=0.25, random_state=2018)\n",
    "\n",
    "    def build_mldl_model(self, n):\n",
    "        if n == '1.0':\n",
    "            # Default DT\n",
    "            self.model = DecisionTreeClassifier()\n",
    "        if n == '1.a1':\n",
    "            # DT/criterion (default='gini')\n",
    "            self.model = DecisionTreeClassifier(criterion='entropy')\n",
    "        if n == '1.a2':\n",
    "            # DT/criterion (default='gini')\n",
    "            self.model = DecisionTreeClassifier(criterion='log_loss')\n",
    "        if n == '1.b1':\n",
    "            # DT/splitter (default='best')\n",
    "            self.model = DecisionTreeClassifier(splitter='best')\n",
    "        if n == '1.c1':\n",
    "            # DT/max_depth (default=None=Infinite)\n",
    "            self.model = DecisionTreeClassifier(max_depth=1)\n",
    "        if n == '1.d1':\n",
    "            # DT/min_samples_split (default=2, must be greater than 2)\n",
    "            self.model = DecisionTreeClassifier(min_samples_split=5)\n",
    "        if n == '1.d2':\n",
    "            # DT/min_samples_split (default=2, must be greater than 2)\n",
    "            self.model = DecisionTreeClassifier(min_samples_split=10)\n",
    "        if n == '1.e1':\n",
    "            # DT/min_weight_fraction_leaf (default=0.0, must be <= 0.5)\n",
    "            self.model = DecisionTreeClassifier(min_weight_fraction_leaf=0.1)\n",
    "        if n == '1.e2':\n",
    "            # DT/min_weight_fraction_leaf (default=0.0, must be <= 0.5)\n",
    "            self.model = DecisionTreeClassifier(min_weight_fraction_leaf=0.5)\n",
    "        if n == '1.f1':\n",
    "            # DT/max_features (default=None)\n",
    "            self.model = DecisionTreeClassifier(max_features=1)\n",
    "        if n == '1.f2':\n",
    "            # DT/max_features (default=None)\n",
    "            self.model = DecisionTreeClassifier(max_features=10)\n",
    "        if n == '1.f3':\n",
    "            # DT/max_features (default=None, if float must < 1)\n",
    "            self.model = DecisionTreeClassifier(max_features=0.1)\n",
    "        if n == '1.f4':\n",
    "            # DT/max_features (default=None, if float must < 1)\n",
    "            self.model = DecisionTreeClassifier(max_features=0.9)\n",
    "        if n == '1.f5':\n",
    "            # DT/max_features (default=None)\n",
    "            self.model = DecisionTreeClassifier(max_features=\"auto\")\n",
    "        if n == '1.f6':\n",
    "            # DT/max_features (default=None)\n",
    "            self.model = DecisionTreeClassifier(max_features=\"sqrt\")\n",
    "        if n == '1.f7':\n",
    "            # DT/max_features (default=None)\n",
    "            self.model = DecisionTreeClassifier(max_features=\"log2\")\n",
    "        if n == '1.g1':\n",
    "            # DT/random_state (default=None)\n",
    "            self.model = DecisionTreeClassifier(random_state=1)\n",
    "        if n == '1.g2':\n",
    "            # DT/random_state (default=None)\n",
    "            self.model = DecisionTreeClassifier(random_state=10)\n",
    "        if n == '1.h1':\n",
    "            # DT/max_leaf_nodes (default=None, must be >= 2)\n",
    "            self.model = DecisionTreeClassifier(max_leaf_nodes=2)\n",
    "        if n == '1.h2':\n",
    "            # DT/max_leaf_nodes (default=None, must be >= 2)\n",
    "            self.model = DecisionTreeClassifier(max_leaf_nodes=10)\n",
    "        if n == '1.i1':\n",
    "            # DT/min_impurity_decrease (default=0.0)\n",
    "            self.model = DecisionTreeClassifier(min_impurity_decrease=0.1)\n",
    "        if n == '1.i2':\n",
    "            # DT/min_impurity_decrease (default=0.0)\n",
    "            self.model = DecisionTreeClassifier(min_impurity_decrease=9.9)\n",
    "        if n == '1.j1':\n",
    "            # DT/class_weight (default=None, dict, list are skipped)\n",
    "            self.model = DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "        if n == '1.k1':\n",
    "            # DT/ccp_alpha (default=0.0, non-negative float)\n",
    "            self.model = DecisionTreeClassifier(ccp_alpha=0.1)\n",
    "        if n == '1.k2':\n",
    "            # DT/ccp_alpha (default=0.0, non-negative float)\n",
    "            self.model = DecisionTreeClassifier(ccp_alpha=9.9)\n",
    "        if n == '2.0':\n",
    "            self.model = RandomForestClassifier()\n",
    "        if n == '2.a1':\n",
    "            # RF/n_estimators (default=100, int)\n",
    "            self.model = RandomForestClassifier(n_estimators=1)\n",
    "        if n == '2.a2':\n",
    "            # RF/n_estimators (default=100, int)\n",
    "            self.model = RandomForestClassifier(n_estimators=100)\n",
    "        if n == '2.b1':\n",
    "            # RF/criterion (default=\"gini\")\n",
    "            self.model = RandomForestClassifier(criterion=\"entropy\")\n",
    "        if n == '2.b2':\n",
    "            # RF/criterion (default=\"gini\")\n",
    "            self.model = RandomForestClassifier(criterion=\"log_loss\")\n",
    "        if n == '2.c1':\n",
    "            # RF/max_depth (default=None, int)\n",
    "            self.model = RandomForestClassifier(max_depth=1)\n",
    "        if n == '2.d1':\n",
    "            # RF/min_samples_split (default=2, int, float)\n",
    "            self.model = RandomForestClassifier(min_samples_split=3)\n",
    "        if n == '2.d2':\n",
    "            # RF/min_samples_split (default=2, int, float)\n",
    "            self.model = RandomForestClassifier(min_samples_split=10)\n",
    "        if n == '2.e1':\n",
    "            # RF/min_samples_leaf (default=1, int, float)\n",
    "            self.model = RandomForestClassifier(min_samples_leaf=2)\n",
    "        if n == '2.e2':\n",
    "            # RF/min_samples_leaf (default=1, int, float)\n",
    "            self.model = RandomForestClassifier(min_samples_leaf=10)\n",
    "        if n == '2.f1':\n",
    "            # RF/min_weight_fraction_leaf (default=0.0, float, must be <= 0.5)\n",
    "            self.model = RandomForestClassifier(min_weight_fraction_leaf=0.1)\n",
    "        if n == '2.f2':\n",
    "            # RF/min_weight_fraction_leaf (default=0.0, float, must be <= 0.5)\n",
    "            self.model = RandomForestClassifier(min_weight_fraction_leaf=0.5)\n",
    "        if n == '2.g1':\n",
    "            # RF/max_features (default=\"sqrt\", \"log2\", \"None\", int, float)\n",
    "            self.model = RandomForestClassifier(max_features=\"log2\")\n",
    "        if n == '2.g2':\n",
    "            # RF/max_features (default=\"sqrt\", \"log2\", None, int, float)\n",
    "            self.model = RandomForestClassifier(max_features=None)\n",
    "        if n == '2.g3':\n",
    "            # RF/max_features (default=\"sqrt\", \"log2\", \"None\", int, float)\n",
    "            self.model = RandomForestClassifier(max_features=1)\n",
    "        if n == '2.g4':\n",
    "            # RF/max_features (default=\"sqrt\", \"log2\", \"None\", int, float)\n",
    "            self.model = RandomForestClassifier(max_features=0.1)\n",
    "        if n == '2.h1':\n",
    "            # RF/max_leaf_nodes (default=infinite, int)\n",
    "            self.model = RandomForestClassifier(max_leaf_nodes=10)\n",
    "        if n == '2.i1':\n",
    "            # RF/min_impurity_decrease (default=0.0, float)\n",
    "            self.model = RandomForestClassifier(min_impurity_decrease=0.1)\n",
    "        if n == '2.i2':\n",
    "            # RF/min_impurity_decrease (default=0.0, float)\n",
    "            self.model = RandomForestClassifier(min_impurity_decrease=9.9)\n",
    "        if n == '2.j1':\n",
    "            # RF/bootstrap (default=True, bool)\n",
    "            self.model = RandomForestClassifier(bootstrap=False)\n",
    "        if n == '2.k1':\n",
    "            # RF/oob_score (default=False, bool)\n",
    "            self.model = RandomForestClassifier(oob_score=True)\n",
    "#         if n == '2.l1':\n",
    "#             # RF/n_jobs (default=None, int)\n",
    "#             self.model = RandomForestClassifier(n_jobs=-1)\n",
    "#         if n == '2.l2':\n",
    "#             # RF/n_jobs (default=None, int)\n",
    "#             self.model = RandomForestClassifier(n_jobs=1)\n",
    "#         if n == '2.l3':\n",
    "#             # RF/n_jobs (default=None, int)\n",
    "#             self.model = RandomForestClassifier(n_jobs=10)\n",
    "        if n == '2.m1':\n",
    "            # RF/random_state (default=None, int)\n",
    "            self.model = RandomForestClassifier(random_state=1)\n",
    "        if n == '2.m2':\n",
    "            # RF/random_state (default=None, int)\n",
    "            self.model = RandomForestClassifier(random_state=10)\n",
    "        if n == '2.n1':\n",
    "            # RF/verbose (default=None, int)\n",
    "            self.model = RandomForestClassifier(verbose=1)\n",
    "        if n == '2.n2':\n",
    "            # RF/verbose (default=None, int)\n",
    "            self.model = RandomForestClassifier(verbose=10)\n",
    "        if n == '2.o1':\n",
    "            # RF/warm_start (default=False, bool)\n",
    "            self.model = RandomForestClassifier(warm_start=True)\n",
    "        if n == '2.p1':\n",
    "            # RF/class_weight (default=None, \"balanced\", \"balanced_subsample\", dict)\n",
    "            self.model = RandomForestClassifier(class_weight=\"balanced\")\n",
    "        if n == '2.p2':\n",
    "            # RF/class_weight (default=None, \"balanced\", \"balanced_subsample\", dict)\n",
    "            self.model = RandomForestClassifier(class_weight=\"balanced_subsample\")\n",
    "        if n == '2.q1':\n",
    "            # RF/ccp_alpha (default=0.0, non-negative float)\n",
    "            self.model = RandomForestClassifier(ccp_alpha=0.1)\n",
    "        if n == '2.q2':\n",
    "            # RF/ccp_alpha (default=0.0, non-negative float)\n",
    "            self.model = RandomForestClassifier(ccp_alpha=9.9)\n",
    "        if n == '2.r1':\n",
    "            # RF/max_samples (default=None, int, float)\n",
    "            self.model = RandomForestClassifier(max_samples=0.1)\n",
    "        if n == '2.r2':\n",
    "            # RF/max_samples (default=None, int, float)\n",
    "            self.model = RandomForestClassifier(max_samples=1.0)\n",
    "        if n == '3.0':\n",
    "            self.model = KNeighborsClassifier()\n",
    "        if n == '3.a1':\n",
    "            # KNN/n_neighbors (default=5, int)\n",
    "            self.model = KNeighborsClassifier(n_neighbors=1)\n",
    "        if n == '3.a2':\n",
    "            # KNN/n_neighbors (default=5, int)\n",
    "            self.model = KNeighborsClassifier(n_neighbors=10)\n",
    "        if n == '3.b1':\n",
    "            # KNN/weights (default=\"uniform\", \"distance\", callable)\n",
    "            self.model = KNeighborsClassifier(weights=\"distance\")\n",
    "        if n == '3.c1':\n",
    "            # KNN/algorithm (default=\"auto\", \"ball_tree\", \"kd_tree\", \"brute\")\n",
    "            self.model = KNeighborsClassifier(algorithm=\"ball_tree\")\n",
    "        if n == '3.c2':\n",
    "            # KNN/algorithm (default=\"auto\", \"ball_tree\", \"kd_tree\", \"brute\")\n",
    "            self.model = KNeighborsClassifier(algorithm=\"kd_tree\")\n",
    "        if n == '3.c3':\n",
    "            # KNN/algorithm (default=\"auto\", \"ball_tree\", \"kd_tree\", \"brute\")\n",
    "            self.model = KNeighborsClassifier(algorithm=\"brute\")\n",
    "        if n == '3.d1':\n",
    "            # KNN/leaf_size (default=30, int)\n",
    "            self.model = KNeighborsClassifier(leaf_size=1)\n",
    "        if n == '3.d2':\n",
    "            # KNN/leaf_size (default=30, int)\n",
    "            self.model = KNeighborsClassifier(leaf_size=100)\n",
    "        if n == '3.e1':\n",
    "            # KNN/p (default=2, int)\n",
    "            self.model = KNeighborsClassifier(p=1)\n",
    "#         if n == '3.f1':\n",
    "#             # KNN/metric (default=\"minkowski\", str, callable)\n",
    "#             self.model = KNeighborsClassifier(metric=\"precomputed\")\n",
    "#             # unusable, need to be square\n",
    "#         if n == '3.e1':\n",
    "#             # KNN/matric_params (default=None, undocumented)\n",
    "#             self.model = KNeighborsClassifier(matric_params=1)\n",
    "#         if n == '3.e1':\n",
    "#             # KNN/n_jobs (default=None, int)\n",
    "#             # number of parallel jobs to run\n",
    "#             self.model = KNeighborsClassifier(n_jobs=-1)\n",
    "        if n == '4.0':\n",
    "            self.model = SVC()\n",
    "        if n == '4.a1':\n",
    "            # SVC/C (default=1.0, float)\n",
    "            self.model = SVC(C=0.1)\n",
    "        if n == '4.a2':\n",
    "            # SVC/C (default=1.0, float)\n",
    "            self.model = SVC(C=10.0)\n",
    "#         if n == '4.b1':\n",
    "#             # SVC/kernel (default=\"rbf\", \"linear\", \"poly\", \"sigmoid\", \"precomputed\")\n",
    "#             self.model = SVC(kernel=\"linear\")\n",
    "#             # Too slow to compute\n",
    "#         if n == '4.b2':\n",
    "#             # SVC/kernel (default=\"rbf\", \"linear\", \"poly\", \"sigmoid\", \"precomputed\")\n",
    "#             self.model = SVC(kernel=\"poly\")\n",
    "#             # Too slow to compute\n",
    "#         if n == '4.b3':\n",
    "#             # SVC/kernel (default=\"rbf\", \"linear\", \"poly\", \"sigmoid\", \"precomputed\")\n",
    "#             self.model = SVC(kernel=\"sigmoid\")\n",
    "#             # Too slow to compute\n",
    "#         if n == '4.b4':\n",
    "#             # SVC/kernel (default=\"rbf\", \"linear\", \"poly\", \"sigmoid\", \"precomputed\")\n",
    "#             self.model = SVC(kernel=\"precomputed\")\n",
    "#             # Too slow to compute\n",
    "#         if n == '4.c1':\n",
    "#             # SVC/degree (default=3, int, only for poly kernel)\n",
    "#             self.model = SVC(degree=4)\n",
    "        if n == '4.c1':\n",
    "            # SVC/gamma (default=\"scale\", \"auto\", float, for rbf, poly, sigmoid kernel)\n",
    "            self.model = SVC(gamma=\"auto\")\n",
    "#         if n == '4.d1':\n",
    "#             # SVC/coef0 (default=0.0, float, for poly, sigmoid kernel)\n",
    "#             self.model = SVC(coef0=0.1)\n",
    "        if n == '4.e1':\n",
    "            # SVC/shrinking (default=True, bool)\n",
    "            self.model = SVC(shrinking=False)\n",
    "        if n == '4.f1':\n",
    "            # SVC/probability (default=False, bool)\n",
    "            self.model = SVC(probability=True)\n",
    "        if n == '4.g1':\n",
    "            # SVC/tol (default=1e-3, float)\n",
    "            self.model = SVC(tol=1e-1)\n",
    "        if n == '4.h1':\n",
    "            # SVC/cache_sizze (default=200, float, MB)\n",
    "            self.model = SVC(cache_size=400)\n",
    "            \n",
    "            \n",
    "        if n == '4.i1':\n",
    "            # SVC/class_weight (default=None, \"balanced\", dict)\n",
    "            self.model = SVC(class_weight=\"balanced\")\n",
    "        if n == '4.j1':\n",
    "            # SVC/verbose (default=False, book)\n",
    "            self.model = SVC(verbose=True)\n",
    "        if n == '4.k1':\n",
    "            # SVC/max_iter (default=-1, int)\n",
    "            self.model = SVC(max_iter=1)\n",
    "        if n == '4.l1':\n",
    "            # SVC/decision_function_shape (default=\"ovr\", \"ovo\")\n",
    "            self.model = SVC(decision_function_shape=\"ovo\")\n",
    "        if n == '4.m1':\n",
    "            # SVC/break_ties (default=False, bool)\n",
    "            self.model = SVC(break_ties=True)\n",
    "#         if n == '4.n1':\n",
    "#             # SVC/random_state (default=None, int, randomstate instance)\n",
    "#             self.model = SVC(random_state=None)\n",
    "\n",
    "    def training_mldl_model(self):\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def test_mldl_model(self):\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "    def evaluate_the_result(self, n):\n",
    "        if self.y_pred.all == self.y_test.all:\n",
    "            print('Prediction successful, all values are same') if print_result_flag else None\n",
    "        else:\n",
    "            self.y_diff = abs(self.y_pred - self.y_test)\n",
    "            self.y_diff_n = (len(self.y_test)-sum(self.y_diff))/len(self.y_test)*100\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.get_data()\n",
    "        self.set_column_names()\n",
    "        self.make_data_all_numerical()\n",
    "        self.split_data_into_train_test()\n",
    "\n",
    "    def training_and_testing(self, n):\n",
    "        self.build_mldl_model(n)\n",
    "        self.training_mldl_model()\n",
    "        self.test_mldl_model()\n",
    "        self.evaluate_the_result(n)\n",
    "\n",
    "    def single_run(self, n):\n",
    "        self.prepare_data()\n",
    "        self.training_and_testing(n)\n",
    "    \n",
    "    def compare(self, n):\n",
    "        # this method of comparison doesn't provides stable fundation, but relative stable fundation,\n",
    "        #   since \"self.training_and_testing('1.0')\" is calculated everytime.\n",
    "        self.prepare_data()\n",
    "        if '1' in n.split('.'):\n",
    "            self.training_and_testing('1.0')\n",
    "        elif '2' in n.split('.'):\n",
    "            self.training_and_testing('2.0')\n",
    "        elif '3' in n.split('.'):\n",
    "            self.training_and_testing('3.0')\n",
    "        elif '4' in n.split('.'):\n",
    "            self.training_and_testing('4.0')\n",
    "        else:\n",
    "            print('errer')\n",
    "        diff1 = self.y_diff_n\n",
    "        self.training_and_testing(n)\n",
    "        diff2 = self.y_diff_n\n",
    "        self.Tdiff = diff2 - diff1\n",
    "        return self.Tdiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a072d",
   "metadata": {},
   "source": [
    "## Function to execute algorithm\n",
    "1. Provide thread protection.\n",
    "2. Tidy up the codes in comparison sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ea9788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(n):\n",
    "    ao = algorithmOperation()\n",
    "    result = ao.compare(n)\n",
    "    if result > 0:\n",
    "        pm = '+'\n",
    "    elif result == 0:\n",
    "        pm = 'x'\n",
    "    else:\n",
    "        pm = '-'\n",
    "    result = abs(result)\n",
    "    del ao\n",
    "    return [pm, result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c07a9f",
   "metadata": {},
   "source": [
    "## 1 DT Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6c121bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dachu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\tree\\_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dachu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\tree\\_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dt_types = ['criterion=\"entropy\"', 'criterion=\"log_loss\"', 'splitter=random\"', 'max_depth=1', 'min_samples_split=5', \n",
    "            'min_samples_split=10', 'min_weight_fraction_leaf=0.1', 'min_weight_fraction_leaf=0.5', 'max_features=1',\n",
    "            'max_features=10', 'max_features=0.1', 'max_features=0.9', 'max_features=\"auto\"', 'max_features=\"sqrt\"',\n",
    "            'max_features=\"log2\"', 'random_state=1', 'random_state=10', 'max_leaf_nodes=1', 'max_leaf_nodes=10',\n",
    "            'min_impurity_decrase=0.1', 'min_impurity_decrase=9.9', 'class_weight=\"balanced\"', 'ccp_alpha=0.1',\n",
    "            'ccp_alpha=9.9']\n",
    "dt_pm = [c('1.a1')[0], c('1.a2')[0], c('1.b1')[0], c('1.c1')[0], c('1.d1')[0], \n",
    "         c('1.d2')[0], c('1.e1')[0], c('1.e2')[0], c('1.f1')[0], c('1.f2')[0],\n",
    "         c('1.f3')[0], c('1.f4')[0], c('1.f5')[0], c('1.f6')[0], c('1.f7')[0],\n",
    "         c('1.g1')[0], c('1.g2')[0], c('1.h1')[0], c('1.h2')[0], c('1.i1')[0],\n",
    "         c('1.i2')[0], c('1.j1')[0], c('1.k1')[0], c('1.k2')[0]]\n",
    "dt_ans = [c('1.a1')[1], c('1.a2')[1], c('1.b1')[1], c('1.c1')[1], c('1.d1')[1], \n",
    "          c('1.d2')[1], c('1.e1')[1], c('1.e2')[1], c('1.f1')[1], c('1.f2')[1],\n",
    "          c('1.f3')[1], c('1.f4')[1], c('1.f5')[1], c('1.f6')[1], c('1.f7')[1],\n",
    "          c('1.g1')[1], c('1.g2')[1], c('1.h1')[1], c('1.h2')[1], c('1.i1')[1],\n",
    "          c('1.i2')[1], c('1.j1')[1], c('1.k1')[1], c('1.k2')[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c346158",
   "metadata": {},
   "source": [
    "## 2 RF Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "175c748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    }
   ],
   "source": [
    "rf_types = ['n_estimators=1', 'n_estimators=100', 'criterion=\"entropy\"', 'criterion=\"log_loss\"', 'max_depth=1',\n",
    "            'min_samples_split=3', 'min_samples_split=10', 'min_samples_leaf=2', 'min_samples_leaf=10',\n",
    "            'min_weight_fraction_leaf=0.1', 'min_weight_fraction_leaf=9.9', 'max_features=\"log2\"', 'max_features=None',\n",
    "            'max_features=1', 'max_features=0.1', 'max_leaf_nodes=10', 'min_impurity_decrease=0.1', 'min_impurity_decrease=9.9',\n",
    "            'bootstrap=False', 'oob_score=True', 'n_jobs=-1', 'n_jobs=1', 'n_jobs=10', 'random_state=1', 'random_state=10',\n",
    "            'verbose=1', 'verbose=10', 'warm_start=True', 'class_weight=\"balanced\"', 'class_weight=\"balanced_subsample\"',\n",
    "            'ccp_alpha=0.1','ccp_alpha=9.9', 'max_samples=0.1', 'max_samples=1.0']\n",
    "rf_pm = [c('2.a1')[0], c('2.a2')[0], c('2.b1')[0], c('2.b2')[0], c('2.c1')[0], c('2.d1')[0], c('2.d2')[0],\n",
    "         c('2.e1')[0], c('2.e2')[0], c('2.f1')[0], c('2.f2')[0], c('2.g1')[0], c('2.g2')[0], c('2.g3')[0],\n",
    "         c('2.g4')[0], c('2.h1')[0], c('2.i1')[0], c('2.i2')[0], c('2.j1')[0], c('2.k1')[0], None,\n",
    "         None, None, c('2.m1')[0], c('2.m2')[0], c('2.n1')[0], c('2.n2')[0], c('2.o1')[0],\n",
    "         c('2.p1')[0], c('2.p2')[0], c('2.q1')[0], c('2.q2')[0], c('2.r1')[0], c('2.r2')[0]]\n",
    "rf_ans = [c('2.a1')[1], c('2.a2')[1], c('2.b1')[1], c('2.b2')[1], c('2.c1')[1], c('2.d1')[1], c('2.d2')[1],\n",
    "          c('2.e1')[1], c('2.e2')[1], c('2.f1')[1], c('2.f2')[1], c('2.g1')[1], c('2.g2')[1], c('2.g3')[1],\n",
    "          c('2.g4')[1], c('2.h1')[1], c('2.i1')[1], c('2.i2')[1], c('2.j1')[1], c('2.k1')[1], None,\n",
    "          None, None, c('2.m1')[1], c('2.m2')[1], c('2.n1')[1], c('2.n2')[1], c('2.o1')[1],\n",
    "          c('2.p1')[1], c('2.p2')[1], c('2.q1')[1], c('2.q2')[1], c('2.r1')[1], c('2.r2')[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501918a3",
   "metadata": {},
   "source": [
    "## 3 KNN Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50e7e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_types = ['n_neighbors=1', 'n_neighbors=10', 'weights=\"distance\"', 'algorithm=\"ball_tree\"', 'algorithm=\"kd_tree\"',\n",
    "             'algorithm=\"brute\"', 'leaf_size=1', 'leaf_size=100', 'p=1', 'metric=\"precomputed\"', 'matric_params=1',\n",
    "             'n_jobs=-1']\n",
    "knn_pm = [c('3.a1')[0], c('3.a2')[0], c('3.b1')[0], c('3.c1')[0], c('3.c2')[0], c('3.c3')[0], c('3.d1')[0], c('3.d2')[0],\n",
    "          c('3.e1')[0], None, None, None]\n",
    "knn_ans = [c('3.a1')[1], c('3.a2')[1], c('3.b1')[1], c('3.c1')[1], c('3.c2')[1], c('3.c3')[1], c('3.d1')[1], c('3.d2')[1],\n",
    "           c('3.e1')[1], None, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e4716",
   "metadata": {},
   "source": [
    "## 4 SVC Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a66014c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dachu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dachu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svc_types = ['C=0.1', 'C=10.0', 'kernel=\"linear\"', 'kernel=\"poly\"', 'kernel=\"sigmoid\"', 'kernel=\"precomputed\"',\n",
    "             'gamma=\"auto\"', 'coef0=0.1', 'shrinking=False', 'probability=True', 'tol=1e-1', 'cache_sizze=400',\n",
    "             'class_weight=\"balanced\"', 'verbose=True', 'max_iter=1', 'decision_function_shape=\"ovo\"', 'break_ties=True',\n",
    "             'random_state=None']\n",
    "svc_pm = [c('4.a1')[0], c('4.a2')[0], None, None, None, None, c('4.c1')[0], None, c('4.e1')[0], c('4.f1')[0], c('4.g1')[0],\n",
    "          c('4.h1')[0], c('4.i1')[0], c('4.j1')[0], c('4.k1')[0], c('4.l1')[0], c('4.m1')[0], None]\n",
    "svc_ans = [c('4.a1')[1], c('4.a2')[1], None, None, None, None, c('4.c1')[1], None, c('4.e1')[1], c('4.f1')[1], c('4.g1')[1],\n",
    "           c('4.h1')[1], c('4.i1')[1], c('4.j1')[1], c('4.k1')[1], c('4.l1')[1], c('4.m1')[1], None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd94d54",
   "metadata": {},
   "source": [
    "# Sum of Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdcd64",
   "metadata": {},
   "source": [
    "### Function to display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6def835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(types, pm, ans, printflag):\n",
    "    try:\n",
    "        result = pd.DataFrame([types, pm, ans])\n",
    "        result = result.transpose()\n",
    "        result.columns = ['type', 'pm', 'ans']\n",
    "        result = result.sort_values(by=['ans'], ascending=False)\n",
    "        print() if print_result_flag else None\n",
    "        print(result) if print_result_flag else None\n",
    "        print() if print_result_flag else None\n",
    "        result_str = 'Most significant effect parameter: ' + str(result.iloc[0][0].split('=')[0])\n",
    "        return [result_str, result]\n",
    "    except Exception as e:\n",
    "        result_str = 'Parameter error'\n",
    "        print(e)\n",
    "        return result_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511751c1",
   "metadata": {},
   "source": [
    "### Print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9464a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_str = 'DT result:  ' + display_result(dt_types, dt_pm, dt_ans, True)[0]\n",
    "RF_str = 'RF result:  ' + display_result(rf_types, rf_pm, rf_ans, True)[0]\n",
    "KNN_str = 'KNN result: ' + display_result(knn_types, knn_pm, knn_ans, True)[0]\n",
    "SVC_str = 'SVC result: ' + display_result(svc_types, svc_pm, svc_ans, True)[0]\n",
    "DT_detail = display_result(dt_types, dt_pm, dt_ans, True)[1]\n",
    "RF_detail = display_result(rf_types, rf_pm, rf_ans, True)[1]\n",
    "KNN_detail = display_result(knn_types, knn_pm, knn_ans, True)[1]\n",
    "SVC_detail = display_result(svc_types, svc_pm, svc_ans, True)[1]\n",
    "print(DT_str) if print_result_flag else None\n",
    "print(RF_str) if print_result_flag else None\n",
    "print(KNN_str) if print_result_flag else None\n",
    "print(SVC_str) if print_result_flag else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a45a6",
   "metadata": {},
   "source": [
    "### Export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79c99bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All file exported.\n"
     ]
    }
   ],
   "source": [
    "file_num = 5\n",
    "for i in range(1,file_num+1):\n",
    "    with open(\"q1data/result_sum_{0}.txt\".format(i), 'w') as f:\n",
    "        f.write(DT_str + '\\n')\n",
    "        f.write(RF_str + '\\n')\n",
    "        f.write(KNN_str + '\\n')\n",
    "        f.write(SVC_str + '\\n')\n",
    "    s = {'type': ['', ''], 'pm': ['', ''], 'ans': ['', '']}\n",
    "    s = pd.DataFrame(data=s)\n",
    "    detail = pd.concat([DT_detail, s, RF_detail, s, KNN_detail, s, SVC_detail], ignore_index=True)\n",
    "    print(detail) if print_result_flag else None\n",
    "    detail.to_csv(\"q1record/result_detail_{0}.txt\".format(i), header=None, index=None, sep=' ')\n",
    "print('All file exported.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9825019d755ccbed326185a3a31f0b603984893c4f0b0febc2131637b1f63dbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
