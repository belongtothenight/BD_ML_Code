{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef66977",
   "metadata": {},
   "source": [
    "# BCW dataset has 32 columns, including 1 label.   Which features are most sensitive to cancer?   Check correlation between features and label with dataframe's method \"corr\" or anything you think is helpful to determine.  Also find out whethe standard scaler would change the correlation or not.  Make sure to submit your codes and your description of the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3504f54",
   "metadata": {},
   "source": [
    "## Python Class for Function Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b0a1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system, getcwd\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics as stt\n",
    "\n",
    "print_flag = False\n",
    "print_result_flag = False\n",
    "plot_flag = False\n",
    "\n",
    "\n",
    "class algorithmOperation():\n",
    "    def get_data(self):\n",
    "        path = join(getcwd(), 'wdbc.data').replace('\\\\', '/')\n",
    "        self.data = pd.read_csv(path, header=None)\n",
    "        if print_flag:\n",
    "            print(self.data)\n",
    "            print(self.data.shape)\n",
    "            print(self.data.columns)\n",
    "            print(self.data.head())\n",
    "\n",
    "    def set_column_names(self):\n",
    "        column_names = ['id', 'malignant',\n",
    "                        'nucleus_mean', 'nucleus_se', 'nucleus_worst',\n",
    "                        'texture_mean', 'texture_se', 'texture_worst',\n",
    "                        'perimeter_mean', 'perimeter_se', 'perimeter_worst',\n",
    "                        'area_mean', 'area_se', 'area_worst',\n",
    "                        'smoothness_mean', 'smoothness_se', 'smoothness_worst',\n",
    "                        'compactness_mean', 'compactness_se', 'compactness_worst',\n",
    "                        'concavity_mean', 'concavity_se', 'concavity_worst',\n",
    "                        'concave_pts_mean', 'concave_pts_se', 'concave_pts_worst',\n",
    "                        'symmetry_mean', 'symmetry_se', 'symmetry_worst',\n",
    "                        'fractal_dim_mean', 'fractal_dim_se', 'fractal_dim_worst'\n",
    "                        ]\n",
    "\n",
    "        self.data.columns = column_names\n",
    "        if print_flag:\n",
    "            print(self.data.shape)\n",
    "            print(self.data.columns)\n",
    "            print(self.data.head())\n",
    "            self.data.tail(10)\n",
    "\n",
    "    def make_data_all_numerical(self):\n",
    "        self.data['malignant'] = self.data['malignant'].map(\n",
    "            lambda x: 0 if x == 'B' else 1)\n",
    "        if print_flag:\n",
    "            self.data.tail(10)\n",
    "\n",
    "    def split_data_into_train_test(self, sds):\n",
    "        self.X = self.data.drop(columns=['malignant']).values\n",
    "        \n",
    "        if sds:\n",
    "            # for scaled data\n",
    "            ss = StandardScaler()\n",
    "            self.X = ss.fit_transform(self.X)\n",
    "        \n",
    "        self.y = self.data['malignant'].values\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=0.25, random_state=2018)\n",
    "\n",
    "    def build_mldl_model(self, n):\n",
    "        if n == '1.0':\n",
    "            # Default DT\n",
    "            self.model = DecisionTreeClassifier()\n",
    "        if n == '2.0':\n",
    "            self.model = RandomForestClassifier()\n",
    "        if n == '3.0':\n",
    "            self.model = KNeighborsClassifier()\n",
    "        if n == '4.0':\n",
    "            self.model = SVC()\n",
    "\n",
    "    def training_mldl_model(self):\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def test_mldl_model(self):\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "    def evaluate_the_result(self, n):\n",
    "        if self.y_pred.all == self.y_test.all:\n",
    "            print('Prediction successful, all values are same') if print_result_flag else None\n",
    "        else:\n",
    "            self.y_diff = abs(self.y_pred - self.y_test)\n",
    "            self.y_diff_n = (len(self.y_test)-sum(self.y_diff))/len(self.y_test)*100\n",
    "\n",
    "    def prepare_data(self, sds):\n",
    "        self.get_data()\n",
    "        self.set_column_names()\n",
    "        self.make_data_all_numerical()\n",
    "        self.split_data_into_train_test(sds)\n",
    "\n",
    "    def training_and_testing(self, n):\n",
    "        self.build_mldl_model(n)\n",
    "        self.training_mldl_model()\n",
    "        self.test_mldl_model()\n",
    "        self.evaluate_the_result(n)\n",
    "\n",
    "    def corr(self):\n",
    "        self.get_data()\n",
    "        self.set_column_names()\n",
    "        self.make_data_all_numerical()\n",
    "        pearson_result = self.data.corr(method ='pearson')\n",
    "        kendall_result = self.data.corr(method='kendall')\n",
    "        return pearson_result, kendall_result\n",
    "\n",
    "#     def single_run(self, n):\n",
    "#         self.prepare_data(sds)\n",
    "#         self.training_and_testing(n)\n",
    "        \n",
    "    def single_run(self, n, sds):\n",
    "        # n: choosing algorithm\n",
    "        # sds: turn on or off data scalling\n",
    "        self.prepare_data(sds)\n",
    "        if n == 1:\n",
    "            self.training_and_testing('1.0')\n",
    "        elif n == 2:\n",
    "            self.training_and_testing('2.0')\n",
    "        elif n == 3:\n",
    "            self.training_and_testing('3.0')\n",
    "        elif n == 4:\n",
    "            self.training_and_testing('4.0')\n",
    "        else:\n",
    "            print('input errer')\n",
    "        return self.y_diff_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452523a",
   "metadata": {},
   "source": [
    "## Correlation Check (corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acf9f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ao = algorithmOperation()\n",
    "p, k = ao.corr()\n",
    "p.to_csv(\"q2data/result_p.csv\")\n",
    "k.to_csv(\"q2data/result_k.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f64bb00",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a072d",
   "metadata": {},
   "source": [
    "### Function to execute algorithm (Scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea9788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr(n, sds, times):\n",
    "    result = []\n",
    "    for i in range(0, times):\n",
    "        ao = algorithmOperation()\n",
    "        result.append(ao.single_run(n, sds))\n",
    "        del ao\n",
    "    mean = stt.mean(result)\n",
    "#     stdev = stt.stdev(result)\n",
    "#     var = stt.variance(result)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3112068",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "919afd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0          1          2          3\n",
      "algorithm           DT         RF        KNN        SVC\n",
      "unscaled     91.608392  93.356643  74.125874  62.237762\n",
      "scaled       91.608392  93.776224  97.202797  97.202797\n",
      "diff(s-uns)        0.0    0.41958  23.076923  34.965035\n"
     ]
    }
   ],
   "source": [
    "times = 10\n",
    "unscaled = [sr(1, False, times), sr(2, False, times), sr(3, False, times), sr(4, False, times)]\n",
    "scaled = [sr(1, True, times), sr(2, True, times), sr(3, True, times), sr(4, True, times)]\n",
    "algorithm = ['DT', 'RF', 'KNN', 'SVC']\n",
    "diff = [scaled[i]-unscaled[i] for i in range(0, len(algorithm))]\n",
    "result = pd.DataFrame(data=[algorithm, unscaled, scaled, diff], index=['algorithm', 'unscaled', 'scaled', 'diff(s-uns)'])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
